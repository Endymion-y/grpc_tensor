// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: worker.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "worker.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
class RecvTensorRequestDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<RecvTensorRequest> {
} _RecvTensorRequest_default_instance_;
class RecvTensorResponseDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<RecvTensorResponse> {
} _RecvTensorResponse_default_instance_;

namespace protobuf_worker_2eproto {


namespace {

::google::protobuf::Metadata file_level_metadata[2];

}  // namespace

const ::google::protobuf::uint32 TableStruct::offsets[] = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, key_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, tensor_),
};

static const ::google::protobuf::internal::MigrationSchema schemas[] = {
  { 0, -1, sizeof(RecvTensorRequest)},
  { 5, -1, sizeof(RecvTensorResponse)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&_RecvTensorRequest_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_RecvTensorResponse_default_instance_),
};

namespace {

void protobuf_AssignDescriptors() {
  AddDescriptors();
  ::google::protobuf::MessageFactory* factory = NULL;
  AssignDescriptors(
      "worker.proto", schemas, file_default_instances, TableStruct::offsets, factory,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 2);
}

}  // namespace

void TableStruct::Shutdown() {
  _RecvTensorRequest_default_instance_.Shutdown();
  delete file_level_metadata[0].reflection;
  _RecvTensorResponse_default_instance_.Shutdown();
  delete file_level_metadata[1].reflection;
}

void TableStruct::InitDefaultsImpl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::internal::InitProtobufDefaults();
  ::tensorflow::protobuf_tensor_2eproto::InitDefaults();
  _RecvTensorRequest_default_instance_.DefaultConstruct();
  _RecvTensorResponse_default_instance_.DefaultConstruct();
  _RecvTensorResponse_default_instance_.get_mutable()->tensor_ = const_cast< ::tensorflow::TensorProto*>(
      ::tensorflow::TensorProto::internal_default_instance());
}

void InitDefaults() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &TableStruct::InitDefaultsImpl);
}
void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] = {
      "\n\014worker.proto\022\ntensorflow\032\014tensor.proto"
      "\" \n\021RecvTensorRequest\022\013\n\003key\030\001 \001(\003\"=\n\022Re"
      "cvTensorResponse\022\'\n\006tensor\030\001 \001(\0132\027.tenso"
      "rflow.TensorProtoB\003\370\001\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 150);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "worker.proto", &protobuf_RegisterTypes);
  ::tensorflow::protobuf_tensor_2eproto::AddDescriptors();
  ::google::protobuf::internal::OnShutdown(&TableStruct::Shutdown);
}

void AddDescriptors() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;

}  // namespace protobuf_worker_2eproto


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RecvTensorRequest::kKeyFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RecvTensorRequest::RecvTensorRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_worker_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RecvTensorRequest)
}
RecvTensorRequest::RecvTensorRequest(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_worker_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RecvTensorRequest)
}
RecvTensorRequest::RecvTensorRequest(const RecvTensorRequest& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  key_ = from.key_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.RecvTensorRequest)
}

void RecvTensorRequest::SharedCtor() {
  key_ = GOOGLE_LONGLONG(0);
  _cached_size_ = 0;
}

RecvTensorRequest::~RecvTensorRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.RecvTensorRequest)
  SharedDtor();
}

void RecvTensorRequest::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

}

void RecvTensorRequest::ArenaDtor(void* object) {
  RecvTensorRequest* _this = reinterpret_cast< RecvTensorRequest* >(object);
  (void)_this;
}
void RecvTensorRequest::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void RecvTensorRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RecvTensorRequest::descriptor() {
  protobuf_worker_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_worker_2eproto::file_level_metadata[0].descriptor;
}

const RecvTensorRequest& RecvTensorRequest::default_instance() {
  protobuf_worker_2eproto::InitDefaults();
  return *internal_default_instance();
}

RecvTensorRequest* RecvTensorRequest::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<RecvTensorRequest>(arena);
}

void RecvTensorRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RecvTensorRequest)
  key_ = GOOGLE_LONGLONG(0);
}

bool RecvTensorRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RecvTensorRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // int64 key = 1;
      case 1: {
        if (static_cast<::google::protobuf::uint8>(tag) ==
            static_cast<::google::protobuf::uint8>(8u)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &key_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RecvTensorRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RecvTensorRequest)
  return false;
#undef DO_
}

void RecvTensorRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RecvTensorRequest)
  // int64 key = 1;
  if (this->key() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->key(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RecvTensorRequest)
}

::google::protobuf::uint8* RecvTensorRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RecvTensorRequest)
  // int64 key = 1;
  if (this->key() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->key(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RecvTensorRequest)
  return target;
}

size_t RecvTensorRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RecvTensorRequest)
  size_t total_size = 0;

  // int64 key = 1;
  if (this->key() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->key());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RecvTensorRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RecvTensorRequest)
  GOOGLE_DCHECK_NE(&from, this);
  const RecvTensorRequest* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const RecvTensorRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RecvTensorRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RecvTensorRequest)
    MergeFrom(*source);
  }
}

void RecvTensorRequest::MergeFrom(const RecvTensorRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RecvTensorRequest)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.key() != 0) {
    set_key(from.key());
  }
}

void RecvTensorRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RecvTensorRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RecvTensorRequest::CopyFrom(const RecvTensorRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RecvTensorRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RecvTensorRequest::IsInitialized() const {
  return true;
}

void RecvTensorRequest::Swap(RecvTensorRequest* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    RecvTensorRequest* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void RecvTensorRequest::UnsafeArenaSwap(RecvTensorRequest* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void RecvTensorRequest::InternalSwap(RecvTensorRequest* other) {
  std::swap(key_, other->key_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RecvTensorRequest::GetMetadata() const {
  protobuf_worker_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_worker_2eproto::file_level_metadata[0];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RecvTensorRequest

// int64 key = 1;
void RecvTensorRequest::clear_key() {
  key_ = GOOGLE_LONGLONG(0);
}
::google::protobuf::int64 RecvTensorRequest::key() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorRequest.key)
  return key_;
}
void RecvTensorRequest::set_key(::google::protobuf::int64 value) {
  
  key_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorRequest.key)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

void RecvTensorResponse::_slow_mutable_tensor() {
  tensor_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorProto >(
      GetArenaNoVirtual());
}
::tensorflow::TensorProto* RecvTensorResponse::_slow_release_tensor() {
  if (tensor_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::TensorProto* temp = new ::tensorflow::TensorProto(*tensor_);
    tensor_ = NULL;
    return temp;
  }
}
::tensorflow::TensorProto* RecvTensorResponse::unsafe_arena_release_tensor() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.RecvTensorResponse.tensor)
  
  ::tensorflow::TensorProto* temp = tensor_;
  tensor_ = NULL;
  return temp;
}
void RecvTensorResponse::_slow_set_allocated_tensor(
    ::google::protobuf::Arena* message_arena, ::tensorflow::TensorProto** tensor) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*tensor) == NULL) {
      message_arena->Own(*tensor);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*tensor)) {
      ::tensorflow::TensorProto* new_tensor = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorProto >(
            message_arena);
      new_tensor->CopyFrom(**tensor);
      *tensor = new_tensor;
    }
}
void RecvTensorResponse::unsafe_arena_set_allocated_tensor(
    ::tensorflow::TensorProto* tensor) {
  if (GetArenaNoVirtual() == NULL) {
    delete tensor_;
  }
  tensor_ = tensor;
  if (tensor) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.RecvTensorResponse.tensor)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RecvTensorResponse::kTensorFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RecvTensorResponse::RecvTensorResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_worker_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RecvTensorResponse)
}
RecvTensorResponse::RecvTensorResponse(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_worker_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RecvTensorResponse)
}
RecvTensorResponse::RecvTensorResponse(const RecvTensorResponse& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_tensor()) {
    tensor_ = new ::tensorflow::TensorProto(*from.tensor_);
  } else {
    tensor_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.RecvTensorResponse)
}

void RecvTensorResponse::SharedCtor() {
  tensor_ = NULL;
  _cached_size_ = 0;
}

RecvTensorResponse::~RecvTensorResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.RecvTensorResponse)
  SharedDtor();
}

void RecvTensorResponse::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

  if (this != internal_default_instance()) {
    delete tensor_;
  }
}

void RecvTensorResponse::ArenaDtor(void* object) {
  RecvTensorResponse* _this = reinterpret_cast< RecvTensorResponse* >(object);
  (void)_this;
}
void RecvTensorResponse::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void RecvTensorResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RecvTensorResponse::descriptor() {
  protobuf_worker_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_worker_2eproto::file_level_metadata[1].descriptor;
}

const RecvTensorResponse& RecvTensorResponse::default_instance() {
  protobuf_worker_2eproto::InitDefaults();
  return *internal_default_instance();
}

RecvTensorResponse* RecvTensorResponse::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<RecvTensorResponse>(arena);
}

void RecvTensorResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RecvTensorResponse)
  if (GetArenaNoVirtual() == NULL && tensor_ != NULL) {
    delete tensor_;
  }
  tensor_ = NULL;
}

bool RecvTensorResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RecvTensorResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.TensorProto tensor = 1;
      case 1: {
        if (static_cast<::google::protobuf::uint8>(tag) ==
            static_cast<::google::protobuf::uint8>(10u)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_tensor()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RecvTensorResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RecvTensorResponse)
  return false;
#undef DO_
}

void RecvTensorResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RecvTensorResponse)
  // .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->tensor_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RecvTensorResponse)
}

::google::protobuf::uint8* RecvTensorResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RecvTensorResponse)
  // .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->tensor_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RecvTensorResponse)
  return target;
}

size_t RecvTensorResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RecvTensorResponse)
  size_t total_size = 0;

  // .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->tensor_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RecvTensorResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RecvTensorResponse)
  GOOGLE_DCHECK_NE(&from, this);
  const RecvTensorResponse* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const RecvTensorResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RecvTensorResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RecvTensorResponse)
    MergeFrom(*source);
  }
}

void RecvTensorResponse::MergeFrom(const RecvTensorResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RecvTensorResponse)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_tensor()) {
    mutable_tensor()->::tensorflow::TensorProto::MergeFrom(from.tensor());
  }
}

void RecvTensorResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RecvTensorResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RecvTensorResponse::CopyFrom(const RecvTensorResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RecvTensorResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RecvTensorResponse::IsInitialized() const {
  return true;
}

void RecvTensorResponse::Swap(RecvTensorResponse* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    RecvTensorResponse* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void RecvTensorResponse::UnsafeArenaSwap(RecvTensorResponse* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void RecvTensorResponse::InternalSwap(RecvTensorResponse* other) {
  std::swap(tensor_, other->tensor_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RecvTensorResponse::GetMetadata() const {
  protobuf_worker_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_worker_2eproto::file_level_metadata[1];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RecvTensorResponse

// .tensorflow.TensorProto tensor = 1;
bool RecvTensorResponse::has_tensor() const {
  return this != internal_default_instance() && tensor_ != NULL;
}
void RecvTensorResponse::clear_tensor() {
  if (GetArenaNoVirtual() == NULL && tensor_ != NULL) delete tensor_;
  tensor_ = NULL;
}
const ::tensorflow::TensorProto& RecvTensorResponse::tensor() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorResponse.tensor)
  return tensor_ != NULL ? *tensor_
                         : *::tensorflow::TensorProto::internal_default_instance();
}
::tensorflow::TensorProto* RecvTensorResponse::mutable_tensor() {
  
  if (tensor_ == NULL) {
    _slow_mutable_tensor();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RecvTensorResponse.tensor)
  return tensor_;
}
::tensorflow::TensorProto* RecvTensorResponse::release_tensor() {
  // @@protoc_insertion_point(field_release:tensorflow.RecvTensorResponse.tensor)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_tensor();
  } else {
    ::tensorflow::TensorProto* temp = tensor_;
    tensor_ = NULL;
    return temp;
  }
}
 void RecvTensorResponse::set_allocated_tensor(::tensorflow::TensorProto* tensor) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete tensor_;
  }
  if (tensor != NULL) {
    _slow_set_allocated_tensor(message_arena, &tensor);
  }
  tensor_ = tensor;
  if (tensor) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RecvTensorResponse.tensor)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
